# ![MitoChat](assets/logo.png)ğŸ§¬ MitoChat â€” RAG + Agentic Streamlit Application

**MitoChat** is a Retrieval-Augmented Generation (RAG) application designed to support genomic and clinical knowledge exploration using a GPU-accelerated backend.  

The stack includes:

- A **Streamlit web interface** (frontend)
- A **FastAPI RAG backend** powered by:
  - **vLLM** (GPU-accelerated text generation)
  - **FAISS** (dense retrieval)
  - **MiniLM** (embeddings)
  - **BGE-reranker-base** (cross-encoder reranking)
  - **Helsinki MarianMT** (FR â†” EN translation)
  - **spaCy** (optional, for sentence-level highlighting)
- A modular codebase to later add STT/TTS microservices (Whisper, Kokoro, etc.).

---

## ğŸ“ Repository Structure

```text
.
â”œâ”€â”€ assets/                     
â”œâ”€â”€ data/                       
â”‚   â”œâ”€â”€ index/
â”‚   â”œâ”€â”€ clinvar/
â”‚   â”œâ”€â”€ genereviews/
â”‚   â””â”€â”€ mitocarta/
â”‚
â”œâ”€â”€ models/                     
â”‚   â”œâ”€â”€ sentence-transformers/all-MiniLM-L6-v2/
â”‚   â”œâ”€â”€ BAAI/bge-reranker-base/
â”‚   â”œâ”€â”€ Helsinki-NLP/opus-mt-fr-en/
â”‚   â””â”€â”€ Helsinki-NLP/opus-mt-en-fr/
â”‚
â”œâ”€â”€ prompts/                    
â”‚   â”œâ”€â”€ rewrite_en.yaml
â”‚   â””â”€â”€ rewrite_fr.yaml
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_corpus_and_index_prod.py
â”‚   â”œâ”€â”€ rag_core.py
â”‚   â”œâ”€â”€ fastapi_backend.py
â”‚   â”œâ”€â”€ streamlit_app_frontend.py
â”‚   â”œâ”€â”€ pdf_rendering.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ backend.Dockerfile
â”‚   â”œâ”€â”€ frontend.Dockerfile
â”‚
â”œâ”€â”€ requirements.backend.txt
â”œâ”€â”€ requirements.frontend.txt
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## âš™ï¸ Features

### Backend (FastAPI + RAG)

- French query âœ **FRâ†’EN translation** âœ RAG in English âœ **ENâ†’FR translation**
- **FAISS** dense retrieval
- **MiniLM** embeddings 
- **BGE-reranker-base** reranking
- **vLLM** LLM serving (GPU)
- Optional **spaCy** sentence highlighting

### Frontend (Streamlit)

- Chat UI
- Sends French queries, receives French answers

---

## ğŸ› ï¸ 1. Local Development

### Create virtual env

```bash
python -m venv venv_clean
source venv_clean/bin/activate
```

### Install deps

```bash
pip install -r requirements.backend.txt
pip install -r requirements.frontend.txt
```

Run backend:

```bash
uvicorn scripts.fastapi_backend:app --reload --port 9000
```

Run frontend:

```bash
streamlit run scripts/streamlit_app_frontend.py
```

---

## ğŸ§± 2. Build FAISS Index

```bash
python scripts/build_corpus_and_index_prod.py
```

Index is saved under `data/index/`.

---

## ğŸ³ 3. Docker Setup

### Build backend:

```bash
docker build -f docker/backend.Dockerfile -t mitochat-backend .
```

### Build frontend:

```bash
docker build -f docker/frontend.Dockerfile -t mitochat-frontend .
```

---

## ğŸ§© 4. Docker Compose Deployment

```bash
docker compose up -d --build
```

---

## ğŸ§  GPU Notes

- NVIDIA drivers required
- NVIDIA Docker Toolkit required
- vLLM is installed **inside** the backend container

Test GPU inside container:

```bash
docker exec -it mitochat_backend python3 -c "import torch; print(torch.cuda.is_available())"
```

---

## ğŸŒ FastAPI Endpoints

Visit:

```
http://localhost:9000/docs
```

---

## ğŸ“„ License

MIT License.
